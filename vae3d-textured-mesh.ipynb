{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1451b8e1",
   "metadata": {},
   "source": [
    "## setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fed4561d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "import time\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(''))\n",
    "\n",
    "import torch\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda:0\")\n",
    "    torch.cuda.set_device(device)\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "print(f\"device:{device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7388e6c4",
   "metadata": {},
   "source": [
    "## set hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e8a45ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_ROOT = 'shapenet/shapenetcore_v2/02773838'\n",
    "RESULT_DIR = 'result/shapenet2'\n",
    "NUM_VIEWS = 16\n",
    "Z_DIM = 100\n",
    "Lr = 1e-4\n",
    "MAX_ITER = 100000\n",
    "SAVE_ITER = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8d9c399",
   "metadata": {},
   "source": [
    "## create renderer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c58f496",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch3d.utils import ico_sphere\n",
    "\n",
    "# Util function for loading meshes\n",
    "from pytorch3d.io import load_objs_as_meshes, save_obj, IO\n",
    "\n",
    "# Data structures and functions for rendering\n",
    "from pytorch3d.structures import Meshes\n",
    "from pytorch3d.renderer import (\n",
    "    look_at_view_transform,\n",
    "    OpenGLPerspectiveCameras, \n",
    "    PointLights,\n",
    "    AmbientLights,\n",
    "    DirectionalLights, \n",
    "    Materials, \n",
    "    RasterizationSettings, \n",
    "    MeshRenderer, \n",
    "    MeshRasterizer,  \n",
    "    SoftPhongShader,\n",
    "    SoftSilhouetteShader,\n",
    "    SoftPhongShader,\n",
    "    TexturesVertex\n",
    ")\n",
    "\n",
    "from plot_image_grid import image_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d4d62e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Render3d():\n",
    "    def __init__(self, num_views, device, image_size=64):\n",
    "        # the number of different viewpoints from which we want to render the mesh.\n",
    "        self.num_views = num_views\n",
    "        self.device = device\n",
    "        self.image_size = image_size\n",
    "\n",
    "        # Get a batch of viewing angles. \n",
    "        elev = torch.linspace(0, 360, self.num_views)\n",
    "        azim = torch.linspace(-180, 180, self.num_views)\n",
    "\n",
    "        # Place an ambient lights \n",
    "        self.lights = AmbientLights(device=self.device)\n",
    "\n",
    "        # Initialize an OpenGL perspective camera that represents a batch of different \n",
    "        # viewing angles. All the cameras helper methods support mixed type inputs and \n",
    "        # broadcasting. So we can view the camera from the a distance of dist=2.7, and \n",
    "        # then specify elevation and azimuth angles for each viewpoint as tensors. \n",
    "        R, T = look_at_view_transform(dist=2.7, elev=elev, azim=azim) \n",
    "        self.cameras = OpenGLPerspectiveCameras(device=device, R=R, T=T)\n",
    "        self.silhouette_cameras = OpenGLPerspectiveCameras(device=device, R=R[None, 1, ...], \n",
    "                                          T=T[None, 1, ...]) \n",
    "\n",
    "        # Rasterization settings for silhouette rendering\n",
    "        sigma = 1e-4\n",
    "        raster_settings_silhouette = RasterizationSettings(\n",
    "            image_size=self.image_size, \n",
    "            blur_radius=np.log(1. / 1e-4 - 1.)*sigma, \n",
    "            faces_per_pixel=50,\n",
    "            perspective_correct=False  ## avoid nan in backprop\n",
    "        )\n",
    "\n",
    "        # Silhouette renderer \n",
    "        self.renderer_silhouette = MeshRenderer(\n",
    "            rasterizer=MeshRasterizer(\n",
    "                cameras=self.silhouette_cameras, \n",
    "                raster_settings=raster_settings_silhouette\n",
    "            ),\n",
    "            shader=SoftSilhouetteShader()\n",
    "        )\n",
    "        \n",
    "        # Rasterization settings for normal rendering\n",
    "        raster_settings = RasterizationSettings(\n",
    "            image_size=self.image_size,\n",
    "            blur_radius=np.log(1. / 1e-4 - 1.)*sigma, \n",
    "            faces_per_pixel=50, \n",
    "            perspective_correct=False  ## avoid nan in backprop\n",
    "        )\n",
    "\n",
    "        # normal renderer\n",
    "        self.renderer = MeshRenderer(\n",
    "            rasterizer=MeshRasterizer(\n",
    "                cameras=self.cameras, \n",
    "                raster_settings=raster_settings\n",
    "            ),\n",
    "            shader=SoftPhongShader(device=self.device)\n",
    "        )\n",
    "    \n",
    "    def render(self, mesh):\n",
    "        verts = mesh.verts_packed()\n",
    "        N = verts.shape[0]\n",
    "        center = verts.mean(0)\n",
    "        scale = max((verts - center).abs().max(0)[0])\n",
    "        mesh.offset_verts_(-center)\n",
    "        mesh.scale_verts_((1.0 / float(scale)));\n",
    "        \n",
    "        meshes = mesh.extend(self.num_views)\n",
    "\n",
    "        rendered_images = self.renderer(meshes, cameras=self.cameras, lights=self.lights)\n",
    "        return torch.clamp(rendered_images.unsqueeze(dim=0), min=0.001, max=0.999) # avoid nan in backprop\n",
    "    \n",
    "    def show_rendered_imgs(self, renderd_imgs, isSave=True, f_name='rgb'):\n",
    "        plt.figure(figsize=(6,6))\n",
    "        for x in range(4*4):\n",
    "            plt.subplot(4, 4, x+1)\n",
    "            plt.imshow(res[0, x].cpu().detach().numpy())\n",
    "            plt.axis('off')\n",
    "        \n",
    "        if isSave:\n",
    "            plt.savefig(f'{f_name}.jpg') \n",
    "        else:\n",
    "            plt.show()\n",
    "            \n",
    "    def show_rendered_silhouette(self, renderd_silhouette, isSave=True, f_name='silhouette'):\n",
    "        plt.figure(figsize=(6,6))\n",
    "        for x in range(4*4):\n",
    "            plt.subplot(4, 4, x+1)\n",
    "            plt.imshow(res[0, x].cpu().detach().numpy())\n",
    "            plt.axis('off')\n",
    "        \n",
    "        if isSave:\n",
    "            plt.savefig(f'{f_name}.jpg') \n",
    "        else:\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b58ae6e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "render_s = Render3d(NUM_VIEWS, device, image_size=64)\n",
    "\n",
    "io = IO()\n",
    "try:\n",
    "    mesh = io.load_mesh(f'{DATASET_ROOT}/1b84dededd445058e44a5473032f38f/models/model_normalized.obj', device=device, load_textures=True, create_texture_atlas=True)\n",
    "    print(mesh.verts_packed().shape)\n",
    "    print(mesh.faces_packed().shape)\n",
    "    print(mesh.textures.atlas_padded().shape)\n",
    "\n",
    "    res = render_s.render(mesh)\n",
    "    print(res.shape)\n",
    "\n",
    "    res = render_s.render(mesh)[..., 3]\n",
    "    print('silhouette:', res.shape)\n",
    "    render_s.show_rendered_silhouette(res, f_name=f'{RESULT_DIR}/sample_silhouette')\n",
    "\n",
    "    res = render_s.render(mesh)[..., :3]\n",
    "    print('normal_rgb', res.shape)\n",
    "    render_s.show_rendered_imgs(res, f_name=f'{RESULT_DIR}/sample_render')\n",
    "\n",
    "except IndexError:\n",
    "    print(\"skip training process because this 3d model is broken.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f936b26",
   "metadata": {},
   "source": [
    "## create trainable autoencoder network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22cf4f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class VarAutoEncoder(nn.Module):\n",
    "    def __init__(self, z_dim, num_views, render_s):\n",
    "        super(VarAutoEncoder, self).__init__()\n",
    "        \n",
    "        self.num_views = num_views\n",
    "        self.render_s = render_s\n",
    "        \n",
    "        self.enc_silhouette = nn.Sequential(\n",
    "            nn.Conv2d(num_views, 64, 3, 1, padding='same'),\n",
    "            nn.LeakyReLU(0.3),\n",
    "            nn.Dropout2d(0.25),\n",
    "            \n",
    "            nn.Conv2d(64, 128, 3, 2),\n",
    "            nn.LeakyReLU(0.3),\n",
    "            nn.Dropout2d(0.25),\n",
    "            \n",
    "            nn.Conv2d(128, 128, 3, 2),\n",
    "            nn.LeakyReLU(0.3),\n",
    "            nn.Dropout2d(0.25),\n",
    "            \n",
    "            nn.Conv2d(128, 128, 3, 2),\n",
    "            nn.LeakyReLU(0.3),\n",
    "            nn.Dropout2d(0.25),\n",
    "            \n",
    "            nn.Conv2d(128, 64, 3, 2),\n",
    "            nn.LeakyReLU(0.3),\n",
    "            nn.Dropout2d(0.25),\n",
    "            \n",
    "            nn.Flatten()\n",
    "        )\n",
    "        \n",
    "        self.enc_rgb = nn.Sequential(\n",
    "            nn.Conv2d(num_views*3, 64, 3, 1, padding='same'),\n",
    "            nn.LeakyReLU(0.3),\n",
    "            nn.Dropout2d(0.25),\n",
    "            \n",
    "            nn.Conv2d(64, 128, 3, 2),\n",
    "            nn.LeakyReLU(0.3),\n",
    "            nn.Dropout2d(0.25),\n",
    "            \n",
    "            nn.Conv2d(128, 128, 3, 2),\n",
    "            nn.LeakyReLU(0.3),\n",
    "            nn.Dropout2d(0.25),\n",
    "            \n",
    "            nn.Conv2d(128, 128, 3, 2),\n",
    "            nn.LeakyReLU(0.3),\n",
    "            nn.Dropout2d(0.25),\n",
    "            \n",
    "            nn.Conv2d(128, 64, 3, 2),\n",
    "            nn.LeakyReLU(0.3),\n",
    "            nn.Dropout2d(0.25),\n",
    "            \n",
    "            nn.Flatten()\n",
    "        )\n",
    "        \n",
    "        \n",
    "        self.encmean = nn.Linear(2*64*3*3, z_dim)\n",
    "        self.encvar = nn.Linear(2*64*3*3, z_dim)\n",
    "        \n",
    "        self.dec_verts = nn.Sequential(\n",
    "            nn.Linear(z_dim, 64*3),\n",
    "            nn.LeakyReLU(0.3),\n",
    "            nn.Dropout(0.25),\n",
    "            \n",
    "            nn.Linear(64*3, 64*3),\n",
    "            nn.LeakyReLU(0.3),\n",
    "            nn.Dropout(0.25),\n",
    "            \n",
    "            nn.Linear(64*3, 64*3),\n",
    "            nn.LeakyReLU(0.3),\n",
    "            nn.Dropout(0.25),\n",
    "            \n",
    "            nn.Linear(64*3, 64*3),\n",
    "            nn.LeakyReLU(0.3),\n",
    "            nn.Dropout(0.25),\n",
    "            \n",
    "            nn.Linear(64*3, 162*3),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "        self.dec_textures = nn.Sequential(\n",
    "            nn.Linear(z_dim, 64*3),\n",
    "            nn.LeakyReLU(0.3),\n",
    "            nn.Dropout(0.25),\n",
    "            \n",
    "            nn.Linear(64*3, 64*3),\n",
    "            nn.LeakyReLU(0.3),\n",
    "            nn.Dropout(0.25),\n",
    "            \n",
    "            nn.Linear(64*3, 64*3),\n",
    "            nn.LeakyReLU(0.3),\n",
    "            nn.Dropout(0.25),\n",
    "            \n",
    "            nn.Linear(64*3, 64*3),\n",
    "            nn.LeakyReLU(0.3),\n",
    "            nn.Dropout(0.25),\n",
    "            \n",
    "            nn.Linear(64*3, 162*3),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    def _encoder(self, x_silhouette, x_rgb):\n",
    "        x_silhouette = self.enc_silhouette(x_silhouette)\n",
    "        x_rgb = self.enc_rgb(x_rgb)\n",
    "        x = torch.cat((x_silhouette, x_rgb), 1)\n",
    "        mean = self.encmean(x)\n",
    "        var = F.softplus(self.encvar(x))\n",
    "        return mean, var\n",
    "    \n",
    "    def _sample_z(self, mean, var):\n",
    "        epsilon = torch.randn(mean.shape).to(device)\n",
    "        return mean + torch.sqrt(var) * epsilon\n",
    " \n",
    "    def _decoder(self, z):\n",
    "        new_verts = self.dec_verts(z)\n",
    "        new_verts = torch.reshape(new_verts, (new_verts.shape[1]//3, 3))\n",
    "        new_textures = self.dec_textures(z)\n",
    "        new_textures = torch.reshape(new_textures, (1, new_textures.shape[1]//3, 3))\n",
    "                \n",
    "        mesh = ico_sphere(2, device)\n",
    "        verts_size = mesh.verts_packed().shape[0] \n",
    "        mesh._verts_packed = new_verts\n",
    "        mesh.textures = TexturesVertex(verts_features=new_textures)\n",
    "        return self.render_s.render(mesh)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_silhouette = x[..., 3]\n",
    "        x_rgb = torch.reshape(torch.permute(x[..., :3], (0, 1, 4, 2, 3)), (1, self.num_views*3, x.shape[2], x.shape[3]))\n",
    "        mean, var = self._encoder(x_silhouette, x_rgb)\n",
    "        z = self._sample_z(mean, var)\n",
    "        y = self._decoder(z)\n",
    "        return y\n",
    "    \n",
    "    def loss(self, x):\n",
    "        x_silhouette = x[..., 3]\n",
    "        x_rgb = torch.reshape(torch.permute(x[..., :3], (0, 1, 4, 2, 3)), (1, self.num_views*3, x.shape[2], x.shape[3]))\n",
    "        mean, var = self._encoder(x_silhouette, x_rgb)\n",
    "        \n",
    "        ## KL_loss\n",
    "        KL = -0.5 * torch.mean(torch.sum(1 + torch.log(var) - mean**2 - var))\n",
    "        \n",
    "        z = self._sample_z(mean, var)\n",
    "        y = self._decoder(z)\n",
    "        \n",
    "        ## reconstruction silhouette & rgb_texture loss\n",
    "        reconstruction_silhouette = torch.mean(torch.sum(x[..., 3] * torch.log(y[..., 3]) + (1 - x[..., 3]) * torch.log(1 - y[..., 3])))\n",
    "        reconstruction_rgb = torch.mean(torch.sum(x[..., :3] * torch.log(y[..., :3]) + (1 - x[..., :3]) * torch.log(1 - y[..., :3])))\n",
    "        \n",
    "        lower_bound = [-KL, reconstruction_silhouette, reconstruction_rgb]                                      \n",
    "        return -sum(lower_bound)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37156db2",
   "metadata": {},
   "source": [
    "## train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0aa13e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "\n",
    "render_s = Render3d(NUM_VIEWS, device, image_size=64)\n",
    "model = VarAutoEncoder(Z_DIM, NUM_VIEWS, render_s).to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=Lr)\n",
    "model.train()\n",
    "losses = []\n",
    "\n",
    "import random\n",
    "import glob\n",
    "file_pathes = glob.glob(f'{DATASET_ROOT}/*/models/model_normalized.obj')\n",
    "\n",
    "from torch.autograd import detect_anomaly\n",
    "\n",
    "for i in range(MAX_ITER):\n",
    "#     with detect_anomaly():\n",
    "    mesh = None\n",
    "    while True:\n",
    "        obj_filename = random.choice(file_pathes)\n",
    "        print(obj_filename, end=', ')\n",
    "        try:\n",
    "            mesh = io.load_mesh(obj_filename, device=device, load_textures=True, create_texture_atlas=True)\n",
    "            break\n",
    "        except IndexError:\n",
    "            print(\"skip train process because this 3d model seems be broken.\")\n",
    "            \n",
    "    x = render_s.render(mesh)\n",
    "    model.zero_grad()\n",
    "    y = model(x)\n",
    "    loss = model.loss(x)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    losses.append(loss.cpu().detach().numpy())\n",
    "    print(f'iter:{(i+1)}/{MAX_ITER}, loss:{losses[-1]}')\n",
    "\n",
    "    if (i+1) % SAVE_ITER == 0:\n",
    "        plt.figure(figsize=(12,12))\n",
    "        plt.subplots_adjust(wspace=0, hspace=0)\n",
    "        for idx in range(8*2):\n",
    "            plt.subplot(8, 8, idx+1)\n",
    "            plt.imshow(x[0, idx, ..., 3].cpu().detach().numpy())\n",
    "            plt.axis('off')\n",
    "        for idx in range(8*2):\n",
    "            plt.subplot(8, 8, idx+1+(8*2))\n",
    "            plt.imshow(x[0, idx, ..., :3].cpu().detach().numpy())            \n",
    "            plt.axis('off')\n",
    "        for idx in range(8*2):\n",
    "            plt.subplot(8, 8, idx+1+(8*4))\n",
    "            plt.imshow(y[0, idx, ..., 3].cpu().detach().numpy())\n",
    "            plt.axis('off')\n",
    "        for idx in range(8*2):\n",
    "            plt.subplot(8, 8, idx+1+(8*6))\n",
    "            plt.imshow(y[0, idx, ..., :3].cpu().detach().numpy())\n",
    "            plt.axis('off')\n",
    "        plt.savefig('{}/result_{:07d}.jpg'.format(RESULT_DIR, i+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e85e67b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.plot(losses)\n",
    "plt.savefig(f'{RESULT_DIR}/train_loss.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffeedc2f",
   "metadata": {},
   "source": [
    "## sampling and evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4302f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(2):\n",
    "    z = torch.randn(1, Z_DIM).to(device)\n",
    "    y = model._decoder(z)\n",
    "    \n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.subplots_adjust(wspace=0, hspace=0)\n",
    "    for idx in range(8*2):\n",
    "        plt.subplot(4, 8, idx+1)\n",
    "        plt.imshow(y[0, idx, ..., 3].cpu().detach().numpy())\n",
    "        plt.axis('off')\n",
    "    for idx in range(8*2):\n",
    "        plt.subplot(4, 8, idx+1+(8*2))\n",
    "        plt.imshow(y[0, idx, ..., :3].cpu().detach().numpy())\n",
    "        plt.axis('off')\n",
    "    plt.savefig('{}/sample_{:07d}.jpg'.format(RESULT_DIR, i+1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
